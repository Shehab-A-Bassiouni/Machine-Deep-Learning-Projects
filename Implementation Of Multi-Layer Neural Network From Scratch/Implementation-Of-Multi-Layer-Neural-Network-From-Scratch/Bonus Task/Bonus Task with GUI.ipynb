{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c551b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import ttk as ttk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f9630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class task_3():\n",
    "    \n",
    "\n",
    "    def preprocess_data(self):\n",
    "        df_train=pd.read_csv(\"mnist_train.csv\")\n",
    "        df_test = pd.read_csv(\"mnist_test.csv\")\n",
    "        \n",
    "        X_train= df_train.iloc[:, 1:]\n",
    "        \n",
    "        Y_train=df_train.iloc[:, 0]\n",
    "        \n",
    "        X_test =df_test.iloc[:, 1:]\n",
    "        \n",
    "        Y_test = df_test.iloc[:, 0]\n",
    "        \n",
    "        X_train=X_train.to_numpy()\n",
    "        X_test=X_test.to_numpy()\n",
    "        Y_train = Y_train.to_numpy()\n",
    "        Y_test = Y_test.to_numpy()\n",
    "        \n",
    "        \n",
    "        X_train=X_train.T\n",
    "        X_test=X_test.T\n",
    "        \n",
    "        \n",
    "        Y_train = np.resize(Y_train , (Y_train.shape[0],1))\n",
    "        ecoding_train_y = np.zeros((Y_train.shape[0], 10))\n",
    "        ecoding_train_y[np.arange(Y_train.shape[0]), Y_train.flatten()] = 1\n",
    "        Y_train = ecoding_train_y.astype(int)\n",
    "        Y_train=Y_train.T\n",
    "        \n",
    "        \n",
    "        Y_test = np.resize(Y_test , (Y_test.shape[0],1))\n",
    "        ecoding_test_y = np.zeros((Y_test.shape[0], 10))\n",
    "        ecoding_test_y[np.arange(Y_test.shape[0]), Y_test.flatten()] = 1\n",
    "        Y_test = ecoding_test_y.astype(int)\n",
    "        Y_test =Y_test.T\n",
    "        \n",
    "        \n",
    "        \n",
    "        return X_train ,Y_train ,X_test,Y_test\n",
    "        \n",
    "    \n",
    "    \n",
    "    def activation(self,x,actv):\n",
    "        if actv == \"sigmoid\":\n",
    "            return expit(x)\n",
    "\n",
    "        elif actv==\"tanh\":\n",
    "            return np.tanh(x)\n",
    "            \n",
    "        \n",
    "    \n",
    "    def prepare_layers(self ,hidden_layers , X_train ):\n",
    "        np.random.seed(1)\n",
    "        layers_dimentions = []\n",
    "        layers_dimentions.append(X_train.shape[0])\n",
    "        for i in range(0,len(hidden_layers)):\n",
    "             layers_dimentions.append(hidden_layers[i])\n",
    "        layers_dimentions.append(10)\n",
    "        parameters={}\n",
    "        for i in range(1,len(layers_dimentions)):\n",
    "            parameters['W' + str(i)] = np.random.randn(layers_dimentions[i],layers_dimentions[i-1] ) *0.01\n",
    "            parameters['b' + str(i)] = np.zeros((layers_dimentions[i],1))\n",
    "        \n",
    "        return parameters\n",
    "    \n",
    "    def forward(self ,X_train,parameters,activ,bias_or_not):\n",
    "        A = X_train\n",
    "        L=len(parameters) // 2\n",
    "        caching={'A0':A}\n",
    "        for i in range(1,L+1):\n",
    "            W = parameters['W' + str(i)]\n",
    "            b = parameters['b' + str(i)]\n",
    "            if bias_or_not == True:\n",
    "               \n",
    "                \n",
    "                z=np.dot(W,A)+b\n",
    "            else:\n",
    "                z=np.dot(W,A)\n",
    "                \n",
    "            caching['Z' + str(i)]=z\n",
    "            if activ == \"sigmoid\":\n",
    "                A= self.activation(z,\"sigmoid\")\n",
    "            else:\n",
    "                A= self.activation(z,\"tanh\")\n",
    "                \n",
    "            caching['A' + str(i)]=A\n",
    "        \n",
    "        return caching ,A\n",
    "    \n",
    "\n",
    "        \n",
    "    def transform_output(self,Y):\n",
    "        modified_lists = []\n",
    "        for lst in Y:\n",
    "            max_prob = max(lst)\n",
    "            modified_lst = [1 if prob == max_prob else 0 for prob in lst]\n",
    "            modified_lists.append(modified_lst)\n",
    "        modified_lists = np.array(modified_lists)\n",
    "        return modified_lists\n",
    "\n",
    "    def backward(self, parameters,Y_train ,caching ):\n",
    "        gradiants={}\n",
    "        L = len(parameters)//2\n",
    "       \n",
    "        dZ=caching[\"A\"+str(L)] - Y_train\n",
    "        gradiants['dW' + str(L)] = np.dot(dZ,caching['A' + str(L-1)].T) / Y_train.shape[1]\n",
    "        gradiants['db' + str(L)] = np.sum(dZ, axis=1, keepdims=True) / Y_train.shape[1]\n",
    "        \n",
    "        for i in range(L-1,0,-1):\n",
    "            dA = np.dot( parameters['W' + str(i+1)].T,dZ)\n",
    "            dZ = dA * caching['A' + str(i)] * (1 - caching['A' + str(i)])\n",
    "            gradiants['dW' + str(i)] = np.dot(dZ,caching['A' + str(i-1)].T ) / Y_train.shape[1]\n",
    "            gradiants['dW' + str(i)] += (0.001 / Y_train.shape[1])*gradiants['dW' + str(i)]\n",
    "            gradiants['db' + str(i)] = np.sum(dZ, axis=1, keepdims=True) / Y_train.shape[1]\n",
    "        return gradiants\n",
    "         \n",
    "    def update(self,parameters, gradiants, learn_rate):\n",
    "        L = len(parameters) // 2\n",
    "        for i in range(1, L+1):\n",
    "            parameters['W' + str(i)] -= learn_rate * gradiants['dW' + str(i)]\n",
    "            parameters['b' + str(i)] -= learn_rate * gradiants['db' + str(i)]\n",
    "        return parameters\n",
    "    \n",
    "    def train(self ,X_train,Y_train,X_test,Y_test,activ,bias_or_not,learn_rate,epoches,hidden_layers):\n",
    "        parameters = self.prepare_layers(hidden_layers,X_train)\n",
    "        max_accuracy=0\n",
    "        values=parameters\n",
    "        for i in range(0,epoches):\n",
    "            \n",
    "            caching,_=self.forward(X_train,parameters,activ,bias_or_not)\n",
    "            gradiants=self.backward(parameters,Y_train,caching)\n",
    "            parameters=self.update(parameters, gradiants, learn_rate)\n",
    "            result=self.test(X_test,parameters,activ,bias_or_not)\n",
    "            acc = self.accuracy(result,Y_test)\n",
    "            if acc[4] > max_accuracy:\n",
    "                max_accuracy=acc[4]\n",
    "                values=parameters\n",
    "            \n",
    "        print(f\"final result ----- highest accuracy is {max_accuracy}\")\n",
    "        return values\n",
    "    \n",
    "    def test(self,X_test,parameters,activ,bias_or_not):\n",
    "        caching,A = self.forward(X_test,parameters,activ,bias_or_not)\n",
    "        \n",
    "        result=self.transform_output(A.T)\n",
    "        return result\n",
    "    \n",
    "    def accuracy(self,result,labels):\n",
    "        #for class 0\n",
    "        tp=0\n",
    "        fp=0\n",
    "        tn=0\n",
    "        fn=0\n",
    "        labels=self.transform_output(labels.T)\n",
    "        for i in range(0,labels.shape[0]):\n",
    "            if np.argmax(result[i]) == np.argmax(labels[i]):\n",
    "                tp+=1\n",
    "            elif np.argmax(result[i]) == 0 and np.argmax(labels[i])!=0:\n",
    "                fp+=1\n",
    "            \n",
    "            elif np.argmax(result[i]) != 0 and np.argmax(labels[i])!=0:\n",
    "                tn+=1     \n",
    "                \n",
    "            elif np.argmax(result[i]) != 0 and np.argmax(labels[i])==0:\n",
    "                fn+=1\n",
    "                \n",
    "        accuracy = (tp / labels.shape[0] ) * 100\n",
    "        \n",
    "        return tp,fp,tn,fn,accuracy\n",
    "    \n",
    "    def sto_train(self,X_train,Y_train,X_test,Y_test,activ,bias_or_not,learn_rate,epoches,hidden_layers):\n",
    "        \n",
    "        max_accuracy = 0\n",
    "        parameters = self.prepare_layers(hidden_layers,X_train)\n",
    "        values =parameters\n",
    "        counter = 100 \n",
    "        for c in range(0 , int(X_train.shape[1]/100)):\n",
    "            tmp_x = X_train[:,:counter]\n",
    "            tmp_y =Y_train[:,:counter]\n",
    "            for i in range(0,epoches):\n",
    "                caching,_=self.forward(tmp_x,parameters,activ,bias_or_not)\n",
    "                gradiants=self.backward(parameters,tmp_y,caching)\n",
    "                parameters=self.update(parameters, gradiants, learn_rate)\n",
    "            result=self.test(X_test,parameters,activ,bias_or_not)\n",
    "            acc = self.accuracy(result,Y_test)\n",
    "            print(f\"stochastic: For Round {c}, Accuracy is {acc[4]} , tp {acc[0]}, fp {acc[1]}, tn {acc[2]}, fn {acc[3]}\")\n",
    "            counter+=100\n",
    "            if acc[4] > max_accuracy:\n",
    "                max_accuracy=acc[4]\n",
    "                values=parameters\n",
    "        print(f\"final result ----- highest accuracy is {max_accuracy}\")\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d21fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GUI():\n",
    "        \n",
    "    def load_gui(self):\n",
    "        self.root = Tk()\n",
    "        screen_width = self.root.winfo_screenwidth()\n",
    "        screen_height = self.root.winfo_screenheight()\n",
    "        self.screen_x = (screen_width / 2) - (500 / 2)\n",
    "        self.screen_y= (screen_height / 2) - (800 / 2)\n",
    "        self.root.geometry(\"%dx%d+%d+%d\" % (500, 800, 0, 0))\n",
    "\n",
    "        learn_method_label = Label(self.root, text=\"Choose Learn Method :\")\n",
    "        learn_method_label.place(x=10 , y=10)\n",
    "        learn_methods = [\"Stochastic\", \"Full Batch\"]\n",
    "        learn_method_combo = ttk.Combobox(self.root , values = learn_methods)\n",
    "        learn_method_combo.place (x=200 ,y=10)\n",
    "\n",
    "        activation_label = Label(self.root, text=\"Choose Activate Function :\")\n",
    "        activation_label.place(x=10 , y=50)\n",
    "        activations = [\"Sigmoid\", \"Tanh\"]\n",
    "        activation_combo = ttk.Combobox(self.root , values = activations)\n",
    "        activation_combo.place (x=200 ,y=50)\n",
    "        \n",
    "        learning_rate_label = Label(self.root, text=\"Enter Learning Rate :\")\n",
    "        learning_rate_label.place(x=10 , y=90)\n",
    "        learning_rate_input = Entry(self.root)\n",
    "        learning_rate_input.place(x=200 , y=90)\n",
    "        \n",
    "        epoches_label = Label(self.root, text=\"Enter Epoches :\")\n",
    "        epoches_label.place(x=10 , y=130)\n",
    "        epoches_input = Entry(self.root)\n",
    "        epoches_input.place(x=200 , y=130)\n",
    "        \n",
    "        layer_label = Label(self.root, text=\"Enter Hidden Layers :\")\n",
    "        layer_label.place(x=10 , y=170)\n",
    "        layer_input = Entry(self.root)\n",
    "        layer_input.place(x=200 , y=170)\n",
    "        \n",
    "        bias_choice = BooleanVar()\n",
    "        bias_input = Checkbutton(self.root, text=\"Bias or Not ?\" ,variable=bias_choice)\n",
    "        bias_input.place(x=200 , y=210)\n",
    "        \n",
    "        run_btn = Button(self.root , text=\"Run\" ,width=50 ,fg=\"green\" ,command=lambda:self.run_button(learn_method_combo.get(),activation_combo.get(),learning_rate_input.get(),epoches_input.get(),layer_input.get(),bias_choice.get()))\n",
    "        run_btn.place(x=50 , y=250)\n",
    "        self.root.mainloop()\n",
    "        \n",
    "    def run_button(self,learn_method,activation,learning_rate,epoches,layer_input,bias):\n",
    "        learn_way = learn_method\n",
    "        activ = activation\n",
    "        bias_or_not = bias\n",
    "        learn_rate=float(learning_rate)\n",
    "        epoches=int(epoches)\n",
    "        hidden_layers = ast.literal_eval(layer_input)\n",
    "        \n",
    "        \n",
    "        obj = task_3()\n",
    "        X_train ,Y_train ,X_test,Y_test = obj.preprocess_data()\n",
    "        \n",
    "        if learn_way == \"Stochastic\":\n",
    "            parameters=obj.sto_train(X_train,Y_train,X_test,Y_test,activ,bias_or_not,learn_rate,epoches,hidden_layers)\n",
    "        elif learn_way ==\"Full Batch\":\n",
    "            parameters=obj.train(X_train,Y_train,X_test,Y_test,activ,bias_or_not,learn_rate,epoches,hidden_layers)\n",
    "            \n",
    "        result=obj.test(X_test,parameters,activ,bias_or_not)\n",
    "        tp,fp,tn,fn,accuracy = obj.accuracy(result,Y_test)\n",
    "        self.second_window(tp,fp,tn,fn,accuracy)\n",
    "\n",
    "        \n",
    "    def second_window(self,tp,fp,tn,fn,accuracy):\n",
    "        self.new_window_1 = Tk()\n",
    "        self.new_window_1.geometry(\"%dx%d+%d+%d\" % (500, 800, 0, 0))\n",
    "        \n",
    "        #--------------------\n",
    "        tp_label=Label(self.new_window_1, text=\"True Positive\")\n",
    "        tp_label.place(x=10 , y=60)\n",
    "        \n",
    "        tp_label_v=Label(self.new_window_1, text=str(tp))\n",
    "        tp_label_v.place(x=100 , y=60)    \n",
    "        #--------------------\n",
    "        \n",
    "        tn_label=Label(self.new_window_1, text=\"True Negative\")\n",
    "        tn_label.place(x=300 , y=60)\n",
    "        \n",
    "        tn_label_v=Label(self.new_window_1, text=str(tn))\n",
    "        tn_label_v.place(x=400 , y=60)\n",
    "        #--------------------\n",
    "        \n",
    "        fp_label=Label(self.new_window_1, text=\"False Positive\")\n",
    "        fp_label.place(x=10 , y=90)\n",
    "        \n",
    "        fp_label_v=Label(self.new_window_1, text=str(fp))\n",
    "        fp_label_v.place(x=100 , y=90)\n",
    "        #--------------------\n",
    "                \n",
    "        fn_label=Label(self.new_window_1, text=\"False Negative\")\n",
    "        fn_label.place(x=300 , y=90)\n",
    "        \n",
    "        fn_label_v=Label(self.new_window_1, text=str(fn))\n",
    "        fn_label_v.place(x=400 , y=90)\n",
    "        #------------------------------------------------------------------------------------------\n",
    " \n",
    "        \n",
    "        err = Label(self.new_window_1, text=\"Accuracy is \")\n",
    "        err.place(x=10 ,y=150)\n",
    "        err_lbl = Label(self.new_window_1, text=str(accuracy))\n",
    "        err_lbl.place(x=110 ,y=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdebb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stochastic: For Round 0, Accuracy is 50.4 , tp 5040, fp 1013, tn 3810, fn 137\n",
      "stochastic: For Round 1, Accuracy is 60.33 , tp 6033, fp 562, tn 3314, fn 91\n",
      "stochastic: For Round 2, Accuracy is 63.79 , tp 6379, fp 600, tn 2972, fn 49\n"
     ]
    }
   ],
   "source": [
    "gui = GUI()\n",
    "gui.load_gui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b0920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result (tanh)| stochastic | 5 epoches | learn rate 0.1 | layers [5000,4000,3000,1000] | bias\n",
    "#max_accuracy =75 |    tp= 7405     |     fp= 331   |    tn= 2236      |         fn=38\n",
    "\n",
    "# result (tanh)| stochastic | 5 epoches | learn rate 0.1 | layers [5000,4000,3000,1000] | no bias\n",
    "#max_accuracy = 76.5|    tp= 7636     |     tn= 2039   |    fp=  285    |         fn=40\n",
    "\n",
    "# result (sigmoid)| stochastic | 5 epoches | learn rate 0.1 | layers [5000,4000,3000,1000] | bias\n",
    "#max_accuracy =11.5 |    tp= 1135     |     tn= 7885   |    fp= 0     |         fn= 980\n",
    "# result (sigmoid)| stochastic | 5 epoches | learn rate 0.1 | layers [5000,4000,3000,1000] | no bias\n",
    "#max_accuracy =11.5 |    tp=  1135    |     tn=  7885  |    fp=  0    |         fn=980"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
