{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b543c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eac9378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class task_3():\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        df = pd.read_csv(\"penguins.csv\")\n",
    "        \n",
    "        df['gender'] = df['gender'].fillna(df['gender'].mode()[0])\n",
    "        df['gender'] = df['gender'].replace({'male': 0, 'female': 1})\n",
    "        df['gender'] = df['gender'].astype(int)\n",
    "        \n",
    "        df['species'] = df['species'].replace({'Adelie': 0, 'Chinstrap': 1 ,'Gentoo':2})\n",
    "        df['species'] = df['species'].astype(int)\n",
    "        \n",
    "        df_Adelie=df[df.iloc[:, 0] == 0]\n",
    "        df_Gentoo=df[df.iloc[:, 0] == 2]\n",
    "        df_Chinstrap=df[df.iloc[:, 0] == 1]\n",
    "        \n",
    "        df_Adelie_train=df_Adelie.sample(frac=0.6, random_state=10)\n",
    "        df_Adelie_test=df_Adelie.drop(df_Adelie_train.index)\n",
    "            \n",
    "        df_Gentoo_train=df_Gentoo.sample(frac=0.6, random_state=10)\n",
    "        df_Gentoo_test=df_Gentoo.drop(df_Gentoo_train.index)\n",
    "        \n",
    "        \n",
    "        df_Chinstrap_train = df_Chinstrap.sample(frac=0.6, random_state=10)\n",
    "        df_Chinstrap_test=df_Chinstrap.drop(df_Chinstrap_train.index)\n",
    "        \n",
    "        df_train = pd.concat([df_Adelie_train, df_Gentoo_train, df_Chinstrap_train], axis=0, ignore_index=True)\n",
    "        df_test = pd.concat([df_Adelie_test, df_Gentoo_test, df_Chinstrap_test], axis=0, ignore_index=True)\n",
    "        \n",
    "        X_train= df_train.iloc[:, 1:]\n",
    "        \n",
    "        Y_train=df_train.iloc[:, 0]\n",
    "        \n",
    "        X_test =df_test.iloc[:, 1:]\n",
    "        \n",
    "        Y_test = df_test.iloc[:, 0]\n",
    "        \n",
    "        X_train=X_train.to_numpy()\n",
    "        X_test=X_test.to_numpy()\n",
    "        Y_train = Y_train.to_numpy()\n",
    "        Y_test = Y_test.to_numpy()\n",
    "        \n",
    "#         train_num = X_train.shape[0]\n",
    "#         train_indices = np.random.permutation(train_num)\n",
    "#         X_train=X_train[train_indices]\n",
    "#         Y_train=Y_train[train_indices]\n",
    "        \n",
    "#         test_num=X_test.shape[0]\n",
    "#         test_indices = np.random.permutation(test_num)\n",
    "#         X_test=X_test[test_indices]\n",
    "#         Y_test=Y_test[test_indices]\n",
    "        \n",
    "        X_train=X_train.T\n",
    "        X_test=X_test.T\n",
    "        \n",
    "        \n",
    "        Y_train = np.resize(Y_train , (Y_train.shape[0],1))\n",
    "        ecoding_train_y = np.zeros((Y_train.shape[0], 3))\n",
    "        ecoding_train_y[np.arange(Y_train.shape[0]), Y_train.flatten()] = 1\n",
    "        Y_train = ecoding_train_y.astype(int)\n",
    "        Y_train=Y_train.T\n",
    "        \n",
    "        \n",
    "        Y_test = np.resize(Y_test , (Y_test.shape[0],1))\n",
    "        ecoding_test_y = np.zeros((Y_test.shape[0], 3))\n",
    "        ecoding_test_y[np.arange(Y_test.shape[0]), Y_test.flatten()] = 1\n",
    "        Y_test = ecoding_test_y.astype(int)\n",
    "        Y_test =Y_test.T\n",
    "        \n",
    "        \n",
    "        \n",
    "        return X_train ,Y_train ,X_test,Y_test\n",
    "        \n",
    "    \n",
    "    \n",
    "    def activation(self,x,actv):\n",
    "        if actv == \"sigmoid\":\n",
    "            return expit(x)\n",
    "\n",
    "        elif actv==\"tanh\":\n",
    "            return np.tanh(x)\n",
    "            \n",
    "        \n",
    "    \n",
    "    def prepare_layers(self ,hidden_layers , X_train ):\n",
    "        np.random.seed(1)\n",
    "        layers_dimentions = []\n",
    "        layers_dimentions.append(X_train.shape[0])\n",
    "        for i in range(0,len(hidden_layers)):\n",
    "             layers_dimentions.append(hidden_layers[i])\n",
    "        layers_dimentions.append(3)\n",
    "        parameters={}\n",
    "        for i in range(1,len(layers_dimentions)):\n",
    "            parameters['W' + str(i)] = np.random.randn(layers_dimentions[i],layers_dimentions[i-1] ) *0.01\n",
    "            parameters['b' + str(i)] = np.zeros((layers_dimentions[i],1))\n",
    "        \n",
    "        return parameters\n",
    "    \n",
    "    def forward(self ,X_train,parameters,activ,bias_or_not):\n",
    "        A = X_train\n",
    "        L=len(parameters) // 2\n",
    "        caching={'A0':A}\n",
    "        for i in range(1,L+1):\n",
    "            W = parameters['W' + str(i)]\n",
    "            b = parameters['b' + str(i)]\n",
    "            if bias_or_not == True:\n",
    "               \n",
    "                \n",
    "                z=np.dot(W,A)+b\n",
    "            else:\n",
    "                z=np.dot(W,A)\n",
    "                \n",
    "            caching['Z' + str(i)]=z\n",
    "            if activ == \"sigmoid\":\n",
    "                A= self.activation(z,\"sigmoid\")\n",
    "            else:\n",
    "                A= self.activation(z,\"tanh\")\n",
    "                \n",
    "            caching['A' + str(i)]=A\n",
    "        \n",
    "        return caching ,A\n",
    "    \n",
    "\n",
    "        \n",
    "    def transform_output(self,Y):\n",
    "        modified_lists = []\n",
    "        for lst in Y:\n",
    "            max_prob = max(lst)\n",
    "            modified_lst = [1 if prob == max_prob else 0 for prob in lst]\n",
    "            modified_lists.append(modified_lst)\n",
    "        modified_lists = np.array(modified_lists)\n",
    "        return modified_lists\n",
    "\n",
    "    def backward(self, parameters,Y_train ,caching ):\n",
    "        gradiants={}\n",
    "        L = len(parameters)//2\n",
    "       \n",
    "        dZ=caching[\"A\"+str(L)] - Y_train\n",
    "        gradiants['dW' + str(L)] = np.dot(dZ,caching['A' + str(L-1)].T) / Y_train.shape[1]\n",
    "        gradiants['db' + str(L)] = np.sum(dZ, axis=1, keepdims=True) / Y_train.shape[1]\n",
    "        \n",
    "        for i in range(L-1,0,-1):\n",
    "            dA = np.dot( parameters['W' + str(i+1)].T,dZ)\n",
    "            dZ = dA * caching['A' + str(i)] * (1 - caching['A' + str(i)])\n",
    "            gradiants['dW' + str(i)] = np.dot(dZ,caching['A' + str(i-1)].T ) / Y_train.shape[1]\n",
    "            gradiants['dW' + str(i)] += (0.001 / Y_train.shape[1])*gradiants['dW' + str(i)]\n",
    "            gradiants['db' + str(i)] = np.sum(dZ, axis=1, keepdims=True) / Y_train.shape[1]\n",
    "        return gradiants\n",
    "         \n",
    "    def update(self,parameters, gradiants, learn_rate):\n",
    "        L = len(parameters) // 2\n",
    "        for i in range(1, L+1):\n",
    "            parameters['W' + str(i)] -= learn_rate * gradiants['dW' + str(i)]\n",
    "            parameters['b' + str(i)] -= learn_rate * gradiants['db' + str(i)]\n",
    "        return parameters\n",
    "    \n",
    "    def train(self ,X_train,Y_train,activ,bias_or_not,learn_rate,epoches,hidden_layers):\n",
    "        parameters = self.prepare_layers(hidden_layers,X_train)\n",
    "        for i in range(0,epoches):\n",
    "            caching,_=self.forward(X_train,parameters,activ,bias_or_not)\n",
    "            gradiants=self.backward(parameters,Y_train,caching)\n",
    "            parameters=self.update(parameters, gradiants, learn_rate)\n",
    "        \n",
    "        return parameters\n",
    "    \n",
    "    def test(self,X_test,parameters,activ,bias_or_not):\n",
    "        caching,A = self.forward(X_test,parameters,activ,bias_or_not)\n",
    "        \n",
    "        result=self.transform_output(A.T)\n",
    "        return result\n",
    "    \n",
    "    def accuracy(self,result,labels):\n",
    "        #for class 0\n",
    "        tp=0\n",
    "        fp=0\n",
    "        tn=0\n",
    "        fn=0\n",
    "        labels=self.transform_output(labels.T)\n",
    "        \n",
    "        for i in range(0,60):\n",
    "            if np.argmax(result[i]) == np.argmax(labels[i]):\n",
    "                tp+=1\n",
    "            elif np.argmax(result[i]) == 0 and np.argmax(labels[i])!=0:\n",
    "                fp+=1\n",
    "            \n",
    "            elif np.argmax(result[i]) != 0 and np.argmax(labels[i])!=0:\n",
    "                tn+=1     \n",
    "                \n",
    "            elif np.argmax(result[i]) != 0 and np.argmax(labels[i])==0:\n",
    "                fn+=1\n",
    "                \n",
    "        accuracy = (tp / 60 ) * 100\n",
    "        \n",
    "        return tp,fp,tn,fn,accuracy\n",
    "                \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d05321c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 56.666666666666664\n"
     ]
    }
   ],
   "source": [
    "activ = \"tanh\"\n",
    "bias_or_not = True\n",
    "learn_rate=0.01\n",
    "epoches=5000\n",
    "hidden_layers = [10,20,50]\n",
    "obj = task_3()\n",
    "X_train ,Y_train ,X_test,Y_test = obj.preprocess_data()\n",
    "\n",
    "parameters=obj.train(X_train,Y_train,activ,bias_or_not,learn_rate,epoches,hidden_layers)\n",
    "result=obj.test(X_test,parameters,activ,bias_or_not)\n",
    "tp,fp,tn,fn,accuracy = obj.accuracy(result,Y_test)\n",
    "print(f\"Accuracy is {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fcc60fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#Accuracy is 56.666666666666664"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aho)",
   "language": "python",
   "name": "aho"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
